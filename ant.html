<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Interaction with ANT-1e AI</title>
    <script src="https://cdn.jsdelivr.net/npm/annyang@2.6.1/dist/annyang.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/RecordRTC/5.6.2/RecordRTC.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        body {
            background-color: #121212;
            color: #ffffff;
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
        }
        h1 {
            margin-bottom: 20px;
        }
        #response {
            background-color: #1e1e1e;
            padding: 20px;
            border-radius: 10px;
            width: 80%;
            max-width: 600px;
            margin-top: 20px;
        }
        #animation {
            width: 150px;
            height: 150px;
        }
        button {
            background-color: #6200ea;
            color: #ffffff;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            margin: 10px;
        }
        button:disabled {
            background-color: #444444;
            cursor: not-allowed;
        }
        #controls {
            display: flex;
            justify-content: center;
            margin-top: 20px;
        }
        #extra-controls {
            margin-top: 20px;
            display: flex;
            justify-content: space-around;
            width: 80%;
        }
        #camera-feed {
            width: 320px;
            height: 240px;
            display: none;
        }
        video, canvas {
            display: none;
        }
    </style>
</head>
<body>
    <h1>ANT-1e Demo (Preview)</h1>
    <div id="interaction-container">
        <img id="animation" src="https://cdn.dribbble.com/users/583436/screenshots/1698964/media/c6693201f9df28dd386aa2f86fc81775.gif" alt="Listening Animation">
        <video id="camera-feed" autoplay></video>
    </div>
    <div id="controls">
        <button id="start-recording">Start</button>
        <button id="stop-recording" disabled>Stop</button>
    </div>
    <div id="extra-controls">
        <button id="pause-ai" disabled>Pause</button>
        <button id="resume-ai" disabled>Resume</button>
        <button id="show-feed">CAMâšª</button>
        <button id="hide-feed" style="display:none;">CAMðŸ”´</button>
    </div>
    <div id="response"></div>
    <video id="video" width="320" height="240" autoplay></video>
    <canvas id="canvas" width="320" height="240"></canvas>

    <script>
        const API_KEY = 'AIzaSyAP1lu4kiGHDEYQNj6FLdpE8ZjrpKMKw20';
        let recorder;
        let audioContext;
        let isRecording = false;
        let silenceTimeout;
        const silenceThreshold = 3000; // 3 seconds of silence
        let imageCaptureInterval;
        const imageInterval = 1000; // 1 second
        let capturedImages = [];
        let previousMessages = [];
        let aiSpeaking = false;
        let aiPaused = false;
        let currentAudio;

        document.getElementById('start-recording').addEventListener('click', startInteraction);
        document.getElementById('stop-recording').addEventListener('click', stopInteraction);
        document.getElementById('pause-ai').addEventListener('click', pauseAI);
        document.getElementById('resume-ai').addEventListener('click', resumeAI);
        document.getElementById('show-feed').addEventListener('click', showFeed);
        document.getElementById('hide-feed').addEventListener('click', hideFeed);

        function startInteraction() {
            setAnimation('listening');
            startSpeechRecognition();
            startRecording();
            startImageCapture();
            document.getElementById('start-recording').disabled = true;
            document.getElementById('stop-recording').disabled = false;
        }

        function stopInteraction() {
            if (annyang) {
                annyang.abort();
            }
            stopRecording();
            stopImageCapture();
            document.getElementById('start-recording').disabled = false;
            document.getElementById('stop-recording').disabled = true;
            if (currentAudio) {
                currentAudio.pause();
                currentAudio = null;
            }
        }

        function startSpeechRecognition() {
            if (annyang) {
                annyang.removeCommands();
                annyang.addCallback('start', () => {
                    console.log('Speech recognition started');
                    setAnimation('listening');
                });

                annyang.addCallback('end', () => {
                    console.log('Speech recognition ended');
                });

                annyang.addCallback('result', () => {
                    clearTimeout(silenceTimeout);
                    silenceTimeout = setTimeout(() => {
                        if (isRecording) {
                            stopRecording();
                            stopImageCapture();
                        }
                    }, silenceThreshold);

                    if (aiSpeaking) {
                        pauseAI();
                    }
                });

                annyang.addCallback('error', (event) => {
                    console.error('Speech recognition error', event.error);
                });

                annyang.start({ continuous: true });
            }
        }

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    recorder = new RecordRTC(stream, {
                        type: 'audio',
                        mimeType: 'audio/wav',
                        recorderType: RecordRTC.StereoAudioRecorder
                    });

                    recorder.startRecording();
                    isRecording = true;
                    console.log('Recording started');
                })
                .catch(error => {
                    console.error('Error accessing microphone:', error);
                    document.getElementById('response').innerText = 'Error accessing microphone. Please check your permissions and try again.';
                });
        }

        function stopRecording() {
            if (recorder && isRecording) {
                recorder.stopRecording(function() {
                    isRecording = false;
                    let blob = recorder.getBlob();
                    console.log('Recording stopped, sending audio to Gemini');
                    sendAudioToGemini(blob);
                });
            }
        }

        function startImageCapture() {
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    const video = document.getElementById('video');
                    video.srcObject = stream;
                    imageCaptureInterval = setInterval(captureImage, imageInterval);
                })
                .catch(error => {
                    console.error('Error accessing camera:', error);
                });
        }

        function stopImageCapture() {
            clearInterval(imageCaptureInterval);
            const video = document.getElementById('video');
            const stream = video.srcObject;
            if (stream) {
                const tracks = stream.getTracks();
                tracks.forEach(track => track.stop());
                video.srcObject = null;
            }
        }

        function captureImage() {
            const canvas = document.getElementById('canvas');
            const video = document.getElementById('video');
            canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);
            const imageDataURL = canvas.toDataURL('image/png');
            capturedImages.push(imageDataURL);
        }

        async function sendAudioToGemini(audioBlob) {
            setAnimation('processing');

            const reader = new FileReader();
            reader.readAsDataURL(audioBlob);

            reader.onloadend = async () => {
                const base64Audio = reader.result.split(',')[1];
                const imageParts = capturedImages.slice(-5).map(image => ({
                    inline_data: {
                        mime_type: 'image/png',
                        data: image.split(',')[1]
                    }
                }));

                const systemInstruction = {
                    system_instruction: {
                        text: "Engage in a voice conversation with me picking up the tone of voice and loudness while answering any questions. Use the audio for context but do not comment on the user's emotions unless you are 100% sure the emotion is correct. Give answers from 1--35 words or beyond if user asks for more. Act as a conversational assistant and answer all sorts of queries. Your name is Air Parrot Hub Beta or APHB. Use reasoning for every command, meaning do not make stuff up; if you can't understand something, just say you don't know. Do not tell me you cannot see or hear me as you have image recognition and voice recognition built-in. If the audio contains a greeting, reply; if the audio does not contain a question, reply asking something. Please answer the question in the following audio without transcribing or repeating it; please take it as a query. Answer a query with your reasoning on why that might be your answer. Do not repeat answers."
                    }
                };

                const messagePayload = {
                    ...systemInstruction,
                    contents: {
                        parts: [
                            {
                                text: "Here is the audio and image. Follow previous instructions and respond with reasoning as APHB. If the request in unclear ask for more info. if they are not talking to you answer anyway  Do not 'Discribe' what is happning. Do not transcribe audio answer as if you were the person who was asked the question. Please be nice and freindly act like my freind named ANT do not include emojis or other formating in your answer. Act as ANT 1 Enhanced "
                            },
                            ...imageParts,
                            {
                                inline_data: {
                                    mime_type: 'audio/wav',
                                    data: base64Audio
                                }
                            }
                        ]
                    }
                };

                previousMessages.push(messagePayload);

                let success = await trySendToGemini(previousMessages);
                if (!success) {
                    console.warn('Retrying with only the latest message and images');
                    success = await trySendToGemini(messagePayload.contents.parts);
                }

                if (!success) {
                    console.error('Failed to get a valid response from Gemini AI.');
                    document.getElementById('response').innerText = 'Error processing audio. Please try again.';
                }
            };
        }

        async function trySendToGemini(messageParts) {
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-exp-0801:generateContent?key=${API_KEY}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: messageParts }],
                        model: "gemini-1.5-pro-exp-0801"
                    })
                });

                const data = await response.json();
                console.log('Response data:', data);
                if (data && data.candidates && data.candidates.length > 0) {
                    const responseMessage = data.candidates[0].content.parts[0].text;
                    document.getElementById('response').innerHTML = marked.parse(responseMessage);
                    playTextAsSpeech(responseMessage);
                    return true;
                } else {
                    showToast('Error 001 Trying Again...');
                    return false;
                }
            } catch (error) {
                console.error('Error sending audio to Gemini:', error);
                showToast('Error sending audio to ANT. Please try again.');
                return false;
            }
        }

        function playTextAsSpeech(text) {
            if (annyang) {
                annyang.abort();
            }

            const encodedText = encodeURIComponent(text);
            const audioUrl = `https://api.flowery.pw/v1/tts?voice=5baa4c03-7b60-5e86-881e-cc774417e539&text=${encodedText}&speed=1&silence=0&translate=false&audio_format=mp3`;
            currentAudio = new Audio(audioUrl);

            currentAudio.onended = () => {
                setAnimation('listening');
                aiSpeaking = false;
                console.log('TTS playback finished, restarting interaction');
                startInteraction();
            };

            currentAudio.onerror = (e) => {
                console.error('Error playing TTS audio:', e);
                setAnimation('listening');
                aiSpeaking = false;
                startInteraction();
            };

            setAnimation('speaking');
            aiSpeaking = true;
            currentAudio.play().catch(e => {
                console.error('Error playing TTS audio:', e);
                setAnimation('listening');
                aiSpeaking = false;
                startInteraction();
            });

            document.getElementById('pause-ai').disabled = false;
            document.getElementById('resume-ai').disabled = true;
        }

        function pauseAI() {
            if (currentAudio && !aiPaused) {
                currentAudio.pause();
                aiPaused = true;
                document.getElementById('pause-ai').disabled = true;
                document.getElementById('resume-ai').disabled = false;
                console.log('AI paused');
            }
        }

        function resumeAI() {
            if (currentAudio && aiPaused) {
                currentAudio.play();
                aiPaused = false;
                document.getElementById('pause-ai').disabled = false;
                document.getElementById('resume-ai').disabled = true;
                console.log('AI resumed');
            }
        }

        function showFeed() {
            document.getElementById('animation').style.marginRight = '20px';
            document.getElementById('camera-feed').style.display = 'block';
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    const cameraFeed = document.getElementById('camera-feed');
                    cameraFeed.srcObject = stream;
                })
                .catch(error => {
                    console.error('Error accessing camera:', error);
                });

            document.getElementById('show-feed').style.display = 'none';
            document.getElementById('hide-feed').style.display = 'block';
        }

        function hideFeed() {
            const cameraFeed = document.getElementById('camera-feed');
            const stream = cameraFeed.srcObject;
            if (stream) {
                const tracks = stream.getTracks();
                tracks.forEach(track => track.stop());
                cameraFeed.srcObject = null;
            }

            document.getElementById('animation').style.marginRight = '0';
            document.getElementById('camera-feed').style.display = 'none';
            document.getElementById('show-feed').style.display = 'block';
            document.getElementById('hide-feed').style.display = 'none';
        }

        function setAnimation(stage) {
            const animation = document.getElementById('animation');
            if (stage === 'listening') {
                animation.src = 'https://cdn.dribbble.com/users/583436/screenshots/1698964/media/c6693201f9df28dd386aa2f86fc81775.gif';
            } else if (stage === 'processing') {
                animation.src = 'https://cdn.dribbble.com/users/583436/screenshots/2375833/media/ece8b003a8d17add76165a49014620a6.gif';
            } else if (stage === 'speaking') {
                animation.src = 'https://cdn.dribbble.com/users/583436/screenshots/1696376/wavy.gif';
            }
        }

        function showToast(message) {
            const toast = document.createElement('div');
            toast.textContent = message;
            toast.style.position = 'fixed';
            toast.style.bottom = '20px';
            toast.style.left = '50%';
            toast.style.transform = 'translateX(-50%)';
            toast.style.backgroundColor = '#333';
            toast.style.color = '#fff';
            toast.style.padding = '10px 20px';
            toast.style.borderRadius = '5px';
            toast.style.zIndex = '1000';
            document.body.appendChild(toast);

            setTimeout(() => {
                document.body.removeChild(toast);
            }, 3000);
        }
    </script>
</body>
</html>
